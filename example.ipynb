{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, NNConv\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph4JSON=\"graphes_JSON/Graphe(4)_features.json\"\n",
    "\n",
    "edges= extract_mapped_edges_from_json(graph4JSON)\n",
    "feature_matrix_df = extract_node_features_from_json_file(graph4JSON)\n",
    "repartition=extract_optimal_repartition_from_json(graph4JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fan_in</th>\n",
       "      <th>fan_out</th>\n",
       "      <th>depth</th>\n",
       "      <th>cpu_speed</th>\n",
       "      <th>comm_speed</th>\n",
       "      <th>latency</th>\n",
       "      <th>computation_time</th>\n",
       "      <th>n_cpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.41463</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.41463</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>1.65852</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.41463</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.41463</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fan_in  fan_out  depth  cpu_speed  comm_speed   latency  \\\n",
       "node_id                                                            \n",
       "4             1        1      2       5.18        6.48  0.952222   \n",
       "23            1        1      2       5.18        6.48  0.952222   \n",
       "39            4        2      2       5.18        6.48  0.952222   \n",
       "42            1        0      3       5.18        6.48  0.952222   \n",
       "47            1        0      3       5.18        6.48  0.952222   \n",
       "\n",
       "         computation_time  n_cpus  \n",
       "node_id                            \n",
       "4                 0.41463      64  \n",
       "23                0.41463      64  \n",
       "39                1.65852      64  \n",
       "42                0.41463      64  \n",
       "47                0.41463      64  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>original_from</th>\n",
       "      <th>original_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>123</td>\n",
       "      <td>126</td>\n",
       "      <td>218</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>218</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>123</td>\n",
       "      <td>129</td>\n",
       "      <td>218</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>132</td>\n",
       "      <td>134</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     from   to  original_from  original_to\n",
       "0       0  110              4            0\n",
       "1       1  113             23           17\n",
       "2       2    3             39           42\n",
       "3       2    4             39           47\n",
       "4       5   32             77           65\n",
       "..    ...  ...            ...          ...\n",
       "142   123  126            218          230\n",
       "143   123  124            218          222\n",
       "144   123  129            218          236\n",
       "145   132  133             33           34\n",
       "146   132  134             33           36\n",
       "\n",
       "[147 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>assigned_cpu</th>\n",
       "      <th>mapped_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>252</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    original_id  assigned_cpu  mapped_id\n",
       "0             4            15          0\n",
       "1            23            16          1\n",
       "2            39            22          2\n",
       "3            42            23          3\n",
       "4            47             4          4\n",
       "..          ...           ...        ...\n",
       "130         252            25        130\n",
       "131         256             6        131\n",
       "132          33             7        132\n",
       "133          34            10        133\n",
       "134          36             9        134\n",
       "\n",
       "[135 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges\n",
    "from_nodes=edges['from'].values\n",
    "to_nodes=edges['to'].values\n",
    "edge_index = np.array([from_nodes, to_nodes], dtype=np.int64)\n",
    "edge_index_tensor = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "# x_train\n",
    "features=feature_matrix_df.values\n",
    "x = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "# y_train\n",
    "y_target = repartition['assigned_cpu'].values\n",
    "y = torch.tensor(y_target, dtype=torch.long)\n",
    "\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index_tensor, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[135, 8], edge_index=[2, 147], y=[135])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels=8, out_channels=32)  # 8 node features -> 32 hidden\n",
    "        self.lin = torch.nn.Linear(32, 64)  # 64 classes (CPUs)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)  # Each node gathers info from 1-hop neighbors\n",
    "        x = F.relu(x) \n",
    "        embeddings = x.clone()                  # Non-linearity\n",
    "        x = self.lin(x)                # Final layer predicts a class between 0–63\n",
    "        return x,embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GCNConv(8, 32)\n",
       "  (lin): Linear(in_features=32, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: Loss: 14.8860, Accuracy: 0.0148\n",
      "Epoch 10: Loss: 5.2278, Accuracy: 0.0222\n",
      "Epoch 110: Loss: 3.5107, Accuracy: 0.0963\n",
      "Epoch 210: Loss: 3.1022, Accuracy: 0.0815\n",
      "Epoch 310: Loss: 2.9708, Accuracy: 0.1259\n",
      "Epoch 410: Loss: 2.8584, Accuracy: 0.1630\n",
      "Epoch 510: Loss: 2.7133, Accuracy: 0.1852\n",
      "Epoch 610: Loss: 2.5349, Accuracy: 0.2222\n",
      "Epoch 710: Loss: 2.4003, Accuracy: 0.2815\n",
      "Epoch 810: Loss: 2.2914, Accuracy: 0.3185\n",
      "Epoch 910: Loss: 2.1986, Accuracy: 0.3259\n",
      "Epoch 1010: Loss: 2.1093, Accuracy: 0.3704\n",
      "Epoch 1110: Loss: 2.0362, Accuracy: 0.3704\n",
      "Epoch 1210: Loss: 1.9765, Accuracy: 0.3852\n",
      "Epoch 1310: Loss: 1.9241, Accuracy: 0.3852\n",
      "Epoch 1410: Loss: 1.9017, Accuracy: 0.4074\n",
      "Epoch 1510: Loss: 1.8402, Accuracy: 0.4222\n",
      "Epoch 1610: Loss: 1.8049, Accuracy: 0.4370\n",
      "Epoch 1710: Loss: 1.7748, Accuracy: 0.4222\n",
      "Epoch 1810: Loss: 1.7459, Accuracy: 0.4222\n",
      "Epoch 1910: Loss: 1.7185, Accuracy: 0.4444\n",
      "Epoch 2010: Loss: 1.6902, Accuracy: 0.4444\n",
      "Epoch 2110: Loss: 1.6682, Accuracy: 0.4444\n",
      "Epoch 2210: Loss: 1.6505, Accuracy: 0.4370\n",
      "Epoch 2310: Loss: 1.6301, Accuracy: 0.4296\n",
      "Epoch 2410: Loss: 1.6053, Accuracy: 0.4222\n",
      "Epoch 2510: Loss: 1.5891, Accuracy: 0.4593\n",
      "Epoch 2610: Loss: 1.5505, Accuracy: 0.4593\n",
      "Epoch 2710: Loss: 1.5364, Accuracy: 0.4519\n",
      "Epoch 2810: Loss: 1.5367, Accuracy: 0.4593\n",
      "Epoch 2910: Loss: 1.5142, Accuracy: 0.4593\n",
      "Epoch 3010: Loss: 1.4771, Accuracy: 0.4741\n",
      "Epoch 3110: Loss: 1.4708, Accuracy: 0.4667\n",
      "Epoch 3210: Loss: 1.4513, Accuracy: 0.4593\n",
      "Epoch 3310: Loss: 1.4458, Accuracy: 0.4815\n",
      "Epoch 3410: Loss: 1.4193, Accuracy: 0.4815\n",
      "Epoch 3510: Loss: 1.4164, Accuracy: 0.4815\n",
      "Epoch 3610: Loss: 1.4034, Accuracy: 0.4741\n",
      "Epoch 3710: Loss: 1.3786, Accuracy: 0.4815\n",
      "Epoch 3810: Loss: 1.3890, Accuracy: 0.4889\n",
      "Epoch 3910: Loss: 1.3678, Accuracy: 0.4889\n",
      "Epoch 4010: Loss: 1.3723, Accuracy: 0.4963\n",
      "Epoch 4110: Loss: 1.3525, Accuracy: 0.4667\n",
      "Epoch 4210: Loss: 1.3439, Accuracy: 0.5037\n",
      "Epoch 4310: Loss: 1.3452, Accuracy: 0.4889\n",
      "Epoch 4410: Loss: 1.3130, Accuracy: 0.4815\n",
      "Epoch 4510: Loss: 1.3289, Accuracy: 0.4963\n",
      "Epoch 4610: Loss: 1.3026, Accuracy: 0.4815\n",
      "Epoch 4710: Loss: 1.3045, Accuracy: 0.4815\n",
      "Epoch 4810: Loss: 1.2943, Accuracy: 0.4889\n",
      "Epoch 4910: Loss: 1.2732, Accuracy: 0.4889\n",
      "Epoch 5010: Loss: 1.2814, Accuracy: 0.4889\n",
      "Epoch 5110: Loss: 1.2618, Accuracy: 0.4889\n",
      "Epoch 5210: Loss: 1.2565, Accuracy: 0.5111\n",
      "Epoch 5310: Loss: 1.2604, Accuracy: 0.5037\n",
      "Epoch 5410: Loss: 1.2588, Accuracy: 0.4963\n",
      "Epoch 5510: Loss: 1.2456, Accuracy: 0.4889\n",
      "Epoch 5610: Loss: 1.2288, Accuracy: 0.5037\n",
      "Epoch 5710: Loss: 1.2561, Accuracy: 0.4963\n",
      "Epoch 5810: Loss: 1.2328, Accuracy: 0.5111\n",
      "Epoch 5910: Loss: 1.2327, Accuracy: 0.4963\n",
      "Epoch 6010: Loss: 1.2113, Accuracy: 0.5037\n",
      "Epoch 6110: Loss: 1.2300, Accuracy: 0.5111\n",
      "Epoch 6210: Loss: 1.2017, Accuracy: 0.5111\n",
      "Epoch 6310: Loss: 1.2116, Accuracy: 0.4963\n",
      "Epoch 6410: Loss: 1.1925, Accuracy: 0.5037\n",
      "Epoch 6510: Loss: 1.1927, Accuracy: 0.4963\n",
      "Epoch 6610: Loss: 1.1888, Accuracy: 0.5111\n",
      "Epoch 6710: Loss: 1.1828, Accuracy: 0.5111\n",
      "Epoch 6810: Loss: 1.1975, Accuracy: 0.4963\n",
      "Epoch 6910: Loss: 1.1773, Accuracy: 0.5111\n",
      "Epoch 7010: Loss: 1.1706, Accuracy: 0.5111\n",
      "Epoch 7110: Loss: 1.1716, Accuracy: 0.5037\n",
      "Epoch 7210: Loss: 1.1652, Accuracy: 0.5111\n",
      "Epoch 7310: Loss: 1.2350, Accuracy: 0.4815\n",
      "Epoch 7410: Loss: 1.1682, Accuracy: 0.5037\n",
      "Epoch 7510: Loss: 1.1601, Accuracy: 0.5037\n",
      "Epoch 7610: Loss: 1.1656, Accuracy: 0.5111\n",
      "Epoch 7710: Loss: 1.1680, Accuracy: 0.5185\n",
      "Epoch 7810: Loss: 1.1521, Accuracy: 0.4889\n",
      "Epoch 7910: Loss: 1.1584, Accuracy: 0.5111\n",
      "Epoch 8010: Loss: 1.1763, Accuracy: 0.5185\n",
      "Epoch 8110: Loss: 1.1406, Accuracy: 0.5111\n",
      "Epoch 8210: Loss: 1.1375, Accuracy: 0.5333\n",
      "Epoch 8310: Loss: 1.1490, Accuracy: 0.5185\n",
      "Epoch 8410: Loss: 1.1539, Accuracy: 0.5037\n",
      "Epoch 8510: Loss: 1.1719, Accuracy: 0.4963\n",
      "Epoch 8610: Loss: 1.1315, Accuracy: 0.5185\n",
      "Epoch 8710: Loss: 1.1274, Accuracy: 0.5259\n",
      "Epoch 8810: Loss: 1.1467, Accuracy: 0.5111\n",
      "Epoch 8910: Loss: 1.1233, Accuracy: 0.5259\n",
      "Epoch 9010: Loss: 1.1328, Accuracy: 0.5259\n",
      "Epoch 9110: Loss: 1.1366, Accuracy: 0.5333\n",
      "Epoch 9210: Loss: 1.1160, Accuracy: 0.5111\n",
      "Epoch 9310: Loss: 1.1199, Accuracy: 0.5259\n",
      "Epoch 9410: Loss: 1.1299, Accuracy: 0.5333\n",
      "Epoch 9510: Loss: 1.1126, Accuracy: 0.5185\n",
      "Epoch 9610: Loss: 1.1226, Accuracy: 0.5185\n",
      "Epoch 9710: Loss: 1.1223, Accuracy: 0.5259\n",
      "Epoch 9810: Loss: 1.1173, Accuracy: 0.5185\n",
      "Epoch 9910: Loss: 1.1044, Accuracy: 0.5259\n",
      "Epoch 10010: Loss: 1.1028, Accuracy: 0.5259\n",
      "Epoch 10110: Loss: 1.1034, Accuracy: 0.5259\n",
      "Epoch 10210: Loss: 1.1410, Accuracy: 0.4963\n",
      "Epoch 10310: Loss: 1.1069, Accuracy: 0.5111\n",
      "Epoch 10410: Loss: 1.0974, Accuracy: 0.5259\n",
      "Epoch 10510: Loss: 1.1067, Accuracy: 0.5259\n",
      "Epoch 10610: Loss: 1.0989, Accuracy: 0.5407\n",
      "Epoch 10710: Loss: 1.1156, Accuracy: 0.5333\n",
      "Epoch 10810: Loss: 1.0909, Accuracy: 0.5259\n",
      "Epoch 10910: Loss: 1.1014, Accuracy: 0.5333\n",
      "Epoch 11010: Loss: 1.1111, Accuracy: 0.5185\n",
      "Epoch 11110: Loss: 1.0908, Accuracy: 0.5185\n",
      "Epoch 11210: Loss: 1.0878, Accuracy: 0.5333\n",
      "Epoch 11310: Loss: 1.0953, Accuracy: 0.5185\n",
      "Epoch 11410: Loss: 1.0832, Accuracy: 0.5407\n",
      "Epoch 11510: Loss: 1.0899, Accuracy: 0.5259\n",
      "Epoch 11610: Loss: 1.1236, Accuracy: 0.5111\n",
      "Epoch 11710: Loss: 1.0897, Accuracy: 0.5407\n",
      "Epoch 11810: Loss: 1.0809, Accuracy: 0.5259\n",
      "Epoch 11910: Loss: 1.0796, Accuracy: 0.5111\n",
      "Epoch 12010: Loss: 1.1013, Accuracy: 0.5259\n",
      "Epoch 12110: Loss: 1.0981, Accuracy: 0.5111\n",
      "Epoch 12210: Loss: 1.0754, Accuracy: 0.5333\n",
      "Epoch 12310: Loss: 1.1317, Accuracy: 0.5185\n",
      "Epoch 12410: Loss: 1.0695, Accuracy: 0.5407\n",
      "Epoch 12510: Loss: 1.0700, Accuracy: 0.5333\n",
      "Epoch 12610: Loss: 1.1384, Accuracy: 0.5111\n",
      "Epoch 12710: Loss: 1.0667, Accuracy: 0.5333\n",
      "Epoch 12810: Loss: 1.0652, Accuracy: 0.5259\n",
      "Epoch 12910: Loss: 1.0635, Accuracy: 0.5407\n",
      "Epoch 13010: Loss: 1.1560, Accuracy: 0.5111\n",
      "Epoch 13110: Loss: 1.0649, Accuracy: 0.5407\n",
      "Epoch 13210: Loss: 1.0592, Accuracy: 0.5333\n",
      "Epoch 13310: Loss: 1.0587, Accuracy: 0.5333\n",
      "Epoch 13410: Loss: 1.0684, Accuracy: 0.5407\n",
      "Epoch 13510: Loss: 1.0557, Accuracy: 0.5407\n",
      "Epoch 13610: Loss: 1.0972, Accuracy: 0.5333\n",
      "Epoch 13710: Loss: 1.0532, Accuracy: 0.5333\n",
      "Epoch 13810: Loss: 1.0773, Accuracy: 0.5333\n",
      "Epoch 13910: Loss: 1.0693, Accuracy: 0.5185\n",
      "Epoch 14010: Loss: 1.0587, Accuracy: 0.5259\n",
      "Epoch 14110: Loss: 1.1329, Accuracy: 0.5185\n",
      "Epoch 14210: Loss: 1.0467, Accuracy: 0.5333\n",
      "Epoch 14310: Loss: 1.1111, Accuracy: 0.5259\n",
      "Epoch 14410: Loss: 1.0453, Accuracy: 0.5333\n",
      "Epoch 14510: Loss: 1.0434, Accuracy: 0.5333\n",
      "Epoch 14610: Loss: 1.0678, Accuracy: 0.5481\n",
      "Epoch 14710: Loss: 1.0712, Accuracy: 0.5111\n",
      "Epoch 14810: Loss: 1.0469, Accuracy: 0.5407\n",
      "Epoch 14910: Loss: 1.0466, Accuracy: 0.5407\n",
      "Epoch 15010: Loss: 1.0801, Accuracy: 0.5407\n",
      "Epoch 15110: Loss: 1.0373, Accuracy: 0.5407\n",
      "Epoch 15210: Loss: 1.0986, Accuracy: 0.5111\n",
      "Epoch 15310: Loss: 1.0355, Accuracy: 0.5407\n",
      "Epoch 15410: Loss: 1.0732, Accuracy: 0.5259\n",
      "Epoch 15510: Loss: 1.0512, Accuracy: 0.5556\n",
      "Epoch 15610: Loss: 1.0328, Accuracy: 0.5259\n",
      "Epoch 15710: Loss: 1.0471, Accuracy: 0.5407\n",
      "Epoch 15810: Loss: 1.0478, Accuracy: 0.5481\n",
      "Epoch 15910: Loss: 1.0296, Accuracy: 0.5407\n",
      "Epoch 16010: Loss: 1.0524, Accuracy: 0.5333\n",
      "Epoch 16110: Loss: 1.0545, Accuracy: 0.5407\n",
      "Epoch 16210: Loss: 1.0264, Accuracy: 0.5407\n",
      "Epoch 16310: Loss: 1.0488, Accuracy: 0.5407\n",
      "Epoch 16410: Loss: 1.0359, Accuracy: 0.5407\n",
      "Epoch 16510: Loss: 1.0240, Accuracy: 0.5407\n",
      "Epoch 16610: Loss: 1.0259, Accuracy: 0.5481\n",
      "Epoch 16710: Loss: 1.0731, Accuracy: 0.5259\n",
      "Epoch 16810: Loss: 1.0514, Accuracy: 0.5333\n",
      "Epoch 16910: Loss: 1.0210, Accuracy: 0.5407\n",
      "Epoch 17010: Loss: 1.0198, Accuracy: 0.5407\n",
      "Epoch 17110: Loss: 1.0311, Accuracy: 0.5333\n",
      "Epoch 17210: Loss: 1.0890, Accuracy: 0.5333\n",
      "Epoch 17310: Loss: 1.0178, Accuracy: 0.5407\n",
      "Epoch 17410: Loss: 1.0171, Accuracy: 0.5407\n",
      "Epoch 17510: Loss: 1.0164, Accuracy: 0.5407\n",
      "Epoch 17610: Loss: 1.0157, Accuracy: 0.5481\n",
      "Epoch 17710: Loss: 1.0231, Accuracy: 0.5407\n",
      "Epoch 17810: Loss: 1.0298, Accuracy: 0.5481\n",
      "Epoch 17910: Loss: 1.3170, Accuracy: 0.4889\n",
      "Epoch 18010: Loss: 1.0123, Accuracy: 0.5407\n",
      "Epoch 18110: Loss: 1.0118, Accuracy: 0.5407\n",
      "Epoch 18210: Loss: 1.0204, Accuracy: 0.5407\n",
      "Epoch 18310: Loss: 1.1006, Accuracy: 0.5185\n",
      "Epoch 18410: Loss: 1.0094, Accuracy: 0.5407\n",
      "Epoch 18510: Loss: 1.0082, Accuracy: 0.5481\n",
      "Epoch 18610: Loss: 1.0100, Accuracy: 0.5481\n",
      "Epoch 18710: Loss: 1.0127, Accuracy: 0.5481\n",
      "Epoch 18810: Loss: 1.0118, Accuracy: 0.5407\n",
      "Epoch 18910: Loss: 1.0051, Accuracy: 0.5481\n",
      "Epoch 19010: Loss: 1.0680, Accuracy: 0.5259\n",
      "Epoch 19110: Loss: 1.0042, Accuracy: 0.5481\n",
      "Epoch 19210: Loss: 1.0022, Accuracy: 0.5481\n",
      "Epoch 19310: Loss: 1.0013, Accuracy: 0.5481\n",
      "Epoch 19410: Loss: 1.0125, Accuracy: 0.5407\n",
      "Epoch 19510: Loss: 1.0023, Accuracy: 0.5481\n",
      "Epoch 19610: Loss: 1.0300, Accuracy: 0.5407\n",
      "Epoch 19710: Loss: 1.0248, Accuracy: 0.5407\n",
      "Epoch 19810: Loss: 0.9976, Accuracy: 0.5556\n",
      "Epoch 19910: Loss: 0.9972, Accuracy: 0.5481\n",
      "Epoch 20010: Loss: 1.0222, Accuracy: 0.5407\n",
      "Epoch 20110: Loss: 1.0036, Accuracy: 0.5407\n",
      "Epoch 20210: Loss: 0.9952, Accuracy: 0.5481\n",
      "Epoch 20310: Loss: 0.9945, Accuracy: 0.5481\n",
      "Epoch 20410: Loss: 0.9939, Accuracy: 0.5481\n",
      "Epoch 20510: Loss: 1.0059, Accuracy: 0.5407\n",
      "Epoch 20610: Loss: 1.0532, Accuracy: 0.5333\n",
      "Epoch 20710: Loss: 0.9919, Accuracy: 0.5556\n",
      "Epoch 20810: Loss: 0.9913, Accuracy: 0.5556\n",
      "Epoch 20910: Loss: 0.9967, Accuracy: 0.5481\n",
      "Epoch 21010: Loss: 1.0098, Accuracy: 0.5481\n",
      "Epoch 21110: Loss: 1.0421, Accuracy: 0.5481\n",
      "Epoch 21210: Loss: 0.9891, Accuracy: 0.5481\n",
      "Epoch 21310: Loss: 1.0435, Accuracy: 0.5185\n",
      "Epoch 21410: Loss: 0.9882, Accuracy: 0.5481\n",
      "Epoch 21510: Loss: 0.9993, Accuracy: 0.5481\n",
      "Epoch 21610: Loss: 1.0048, Accuracy: 0.5481\n",
      "Epoch 21710: Loss: 0.9925, Accuracy: 0.5481\n",
      "Epoch 21810: Loss: 0.9853, Accuracy: 0.5556\n",
      "Epoch 21910: Loss: 0.9844, Accuracy: 0.5556\n",
      "Epoch 22010: Loss: 0.9837, Accuracy: 0.5556\n",
      "Epoch 22110: Loss: 0.9851, Accuracy: 0.5481\n",
      "Epoch 22210: Loss: 0.9941, Accuracy: 0.5407\n",
      "Epoch 22310: Loss: 1.0070, Accuracy: 0.5407\n",
      "Epoch 22410: Loss: 0.9982, Accuracy: 0.5407\n",
      "Epoch 22510: Loss: 0.9875, Accuracy: 0.5556\n",
      "Epoch 22610: Loss: 0.9828, Accuracy: 0.5481\n",
      "Epoch 22710: Loss: 0.9998, Accuracy: 0.5481\n",
      "Epoch 22810: Loss: 1.0310, Accuracy: 0.5185\n",
      "Epoch 22910: Loss: 0.9784, Accuracy: 0.5481\n",
      "Epoch 23010: Loss: 0.9773, Accuracy: 0.5481\n",
      "Epoch 23110: Loss: 0.9862, Accuracy: 0.5556\n",
      "Epoch 23210: Loss: 1.0346, Accuracy: 0.5407\n",
      "Epoch 23310: Loss: 0.9787, Accuracy: 0.5407\n",
      "Epoch 23410: Loss: 0.9749, Accuracy: 0.5556\n",
      "Epoch 23510: Loss: 0.9777, Accuracy: 0.5481\n",
      "Epoch 23610: Loss: 1.1764, Accuracy: 0.5333\n",
      "Epoch 23710: Loss: 0.9732, Accuracy: 0.5556\n",
      "Epoch 23810: Loss: 0.9723, Accuracy: 0.5556\n",
      "Epoch 23910: Loss: 0.9764, Accuracy: 0.5481\n",
      "Epoch 24010: Loss: 0.9969, Accuracy: 0.5407\n",
      "Epoch 24110: Loss: 0.9764, Accuracy: 0.5556\n",
      "Epoch 24210: Loss: 0.9708, Accuracy: 0.5556\n",
      "Epoch 24310: Loss: 0.9991, Accuracy: 0.5407\n",
      "Epoch 24410: Loss: 1.1797, Accuracy: 0.5111\n",
      "Epoch 24510: Loss: 0.9679, Accuracy: 0.5556\n",
      "Epoch 24610: Loss: 0.9672, Accuracy: 0.5556\n",
      "Epoch 24710: Loss: 1.0005, Accuracy: 0.5481\n",
      "Epoch 24810: Loss: 0.9860, Accuracy: 0.5481\n",
      "Epoch 24910: Loss: 0.9858, Accuracy: 0.5481\n",
      "Epoch 25010: Loss: 1.0706, Accuracy: 0.5259\n",
      "Epoch 25110: Loss: 0.9644, Accuracy: 0.5556\n",
      "Epoch 25210: Loss: 0.9669, Accuracy: 0.5556\n",
      "Epoch 25310: Loss: 0.9695, Accuracy: 0.5481\n",
      "Epoch 25410: Loss: 0.9666, Accuracy: 0.5481\n",
      "Epoch 25510: Loss: 0.9873, Accuracy: 0.5481\n",
      "Epoch 25610: Loss: 0.9613, Accuracy: 0.5556\n",
      "Epoch 25710: Loss: 0.9613, Accuracy: 0.5556\n",
      "Epoch 25810: Loss: 0.9630, Accuracy: 0.5556\n",
      "Epoch 25910: Loss: 0.9684, Accuracy: 0.5481\n",
      "Epoch 26010: Loss: 0.9696, Accuracy: 0.5481\n",
      "Epoch 26110: Loss: 1.0788, Accuracy: 0.5185\n",
      "Epoch 26210: Loss: 0.9587, Accuracy: 0.5556\n",
      "Epoch 26310: Loss: 0.9581, Accuracy: 0.5556\n",
      "Epoch 26410: Loss: 0.9606, Accuracy: 0.5481\n",
      "Epoch 26510: Loss: 0.9575, Accuracy: 0.5556\n",
      "Epoch 26610: Loss: 0.9743, Accuracy: 0.5481\n",
      "Epoch 26710: Loss: 0.9634, Accuracy: 0.5481\n",
      "Epoch 26810: Loss: 0.9670, Accuracy: 0.5481\n",
      "Epoch 26910: Loss: 0.9682, Accuracy: 0.5481\n",
      "Epoch 27010: Loss: 0.9624, Accuracy: 0.5481\n",
      "Epoch 27110: Loss: 0.9769, Accuracy: 0.5481\n",
      "Epoch 27210: Loss: 1.1230, Accuracy: 0.5185\n",
      "Epoch 27310: Loss: 0.9554, Accuracy: 0.5556\n",
      "Epoch 27410: Loss: 0.9516, Accuracy: 0.5556\n",
      "Epoch 27510: Loss: 0.9517, Accuracy: 0.5556\n",
      "Epoch 27610: Loss: 0.9644, Accuracy: 0.5481\n",
      "Epoch 27710: Loss: 0.9507, Accuracy: 0.5556\n",
      "Epoch 27810: Loss: 0.9503, Accuracy: 0.5556\n",
      "Epoch 27910: Loss: 0.9952, Accuracy: 0.5481\n",
      "Epoch 28010: Loss: 0.9488, Accuracy: 0.5556\n",
      "Epoch 28110: Loss: 0.9482, Accuracy: 0.5556\n",
      "Epoch 28210: Loss: 0.9712, Accuracy: 0.5481\n",
      "Epoch 28310: Loss: 0.9807, Accuracy: 0.5333\n",
      "Epoch 28410: Loss: 0.9789, Accuracy: 0.5407\n",
      "Epoch 28510: Loss: 0.9482, Accuracy: 0.5556\n",
      "Epoch 28610: Loss: 0.9649, Accuracy: 0.5556\n",
      "Epoch 28710: Loss: 1.0118, Accuracy: 0.5259\n",
      "Epoch 28810: Loss: 0.9445, Accuracy: 0.5556\n",
      "Epoch 28910: Loss: 0.9505, Accuracy: 0.5481\n",
      "Epoch 29010: Loss: 0.9543, Accuracy: 0.5481\n",
      "Epoch 29110: Loss: 0.9539, Accuracy: 0.5481\n",
      "Epoch 29210: Loss: 0.9880, Accuracy: 0.5407\n",
      "Epoch 29310: Loss: 0.9425, Accuracy: 0.5556\n",
      "Epoch 29410: Loss: 0.9444, Accuracy: 0.5556\n",
      "Epoch 29510: Loss: 0.9433, Accuracy: 0.5556\n",
      "Epoch 29610: Loss: 0.9583, Accuracy: 0.5556\n",
      "Epoch 29710: Loss: 0.9503, Accuracy: 0.5556\n",
      "Epoch 29810: Loss: 0.9456, Accuracy: 0.5556\n",
      "Epoch 29910: Loss: 0.9489, Accuracy: 0.5556\n",
      "Epoch 30010: Loss: 0.9561, Accuracy: 0.5481\n",
      "Epoch 30110: Loss: 0.9746, Accuracy: 0.5407\n",
      "Epoch 30210: Loss: 0.9419, Accuracy: 0.5556\n",
      "Epoch 30310: Loss: 0.9497, Accuracy: 0.5481\n",
      "Epoch 30410: Loss: 0.9452, Accuracy: 0.5556\n",
      "Epoch 30510: Loss: 0.9507, Accuracy: 0.5481\n",
      "Epoch 30610: Loss: 0.9695, Accuracy: 0.5481\n",
      "Epoch 30710: Loss: 0.9518, Accuracy: 0.5556\n",
      "Epoch 30810: Loss: 0.9996, Accuracy: 0.5556\n",
      "Epoch 30910: Loss: 0.9349, Accuracy: 0.5630\n",
      "Epoch 31010: Loss: 0.9343, Accuracy: 0.5630\n",
      "Epoch 31110: Loss: 1.0167, Accuracy: 0.5407\n",
      "Epoch 31210: Loss: 0.9470, Accuracy: 0.5556\n",
      "Epoch 31310: Loss: 0.9333, Accuracy: 0.5556\n",
      "Epoch 31410: Loss: 0.9327, Accuracy: 0.5556\n",
      "Epoch 31510: Loss: 0.9337, Accuracy: 0.5556\n",
      "Epoch 31610: Loss: 0.9331, Accuracy: 0.5556\n",
      "Epoch 31710: Loss: 0.9454, Accuracy: 0.5556\n",
      "Epoch 31810: Loss: 1.6039, Accuracy: 0.4889\n",
      "Epoch 31910: Loss: 0.9307, Accuracy: 0.5630\n",
      "Epoch 32010: Loss: 0.9305, Accuracy: 0.5630\n",
      "Epoch 32110: Loss: 0.9495, Accuracy: 0.5556\n",
      "Epoch 32210: Loss: 0.9399, Accuracy: 0.5556\n",
      "Epoch 32310: Loss: 0.9501, Accuracy: 0.5556\n",
      "Epoch 32410: Loss: 0.9441, Accuracy: 0.5481\n",
      "Epoch 32510: Loss: 0.9430, Accuracy: 0.5556\n",
      "Epoch 32610: Loss: 0.9316, Accuracy: 0.5556\n",
      "Epoch 32710: Loss: 0.9379, Accuracy: 0.5556\n",
      "Epoch 32810: Loss: 0.9412, Accuracy: 0.5556\n",
      "Epoch 32910: Loss: 0.9353, Accuracy: 0.5481\n",
      "Epoch 33010: Loss: 1.0218, Accuracy: 0.5407\n",
      "Epoch 33110: Loss: 0.9787, Accuracy: 0.5407\n",
      "Epoch 33210: Loss: 0.9261, Accuracy: 0.5556\n",
      "Epoch 33310: Loss: 0.9253, Accuracy: 0.5630\n",
      "Epoch 33410: Loss: 0.9310, Accuracy: 0.5556\n",
      "Epoch 33510: Loss: 0.9250, Accuracy: 0.5630\n",
      "Epoch 33610: Loss: 0.9332, Accuracy: 0.5630\n",
      "Epoch 33710: Loss: 0.9234, Accuracy: 0.5630\n",
      "Epoch 33810: Loss: 0.9405, Accuracy: 0.5556\n",
      "Epoch 33910: Loss: 0.9569, Accuracy: 0.5481\n",
      "Epoch 34010: Loss: 0.9261, Accuracy: 0.5556\n",
      "Epoch 34110: Loss: 1.0275, Accuracy: 0.5481\n",
      "Epoch 34210: Loss: 0.9223, Accuracy: 0.5630\n",
      "Epoch 34310: Loss: 0.9314, Accuracy: 0.5556\n",
      "Epoch 34410: Loss: 1.0029, Accuracy: 0.5333\n",
      "Epoch 34510: Loss: 0.9232, Accuracy: 0.5630\n",
      "Epoch 34610: Loss: 0.9210, Accuracy: 0.5630\n",
      "Epoch 34710: Loss: 0.9337, Accuracy: 0.5481\n",
      "Epoch 34810: Loss: 0.9278, Accuracy: 0.5630\n",
      "Epoch 34910: Loss: 0.9202, Accuracy: 0.5630\n",
      "Epoch 35010: Loss: 0.9193, Accuracy: 0.5630\n",
      "Epoch 35110: Loss: 0.9187, Accuracy: 0.5630\n",
      "Epoch 35210: Loss: 0.9182, Accuracy: 0.5630\n",
      "Epoch 35310: Loss: 0.9182, Accuracy: 0.5630\n",
      "Epoch 35410: Loss: 0.9365, Accuracy: 0.5556\n",
      "Epoch 35510: Loss: 1.0632, Accuracy: 0.5185\n",
      "Epoch 35610: Loss: 0.9462, Accuracy: 0.5481\n",
      "Epoch 35710: Loss: 0.9251, Accuracy: 0.5556\n",
      "Epoch 35810: Loss: 0.9256, Accuracy: 0.5556\n",
      "Epoch 35910: Loss: 0.9221, Accuracy: 0.5630\n",
      "Epoch 36010: Loss: 1.5409, Accuracy: 0.4889\n",
      "Epoch 36110: Loss: 0.9174, Accuracy: 0.5630\n",
      "Epoch 36210: Loss: 0.9151, Accuracy: 0.5630\n",
      "Epoch 36310: Loss: 0.9145, Accuracy: 0.5630\n",
      "Epoch 36410: Loss: 0.9145, Accuracy: 0.5630\n",
      "Epoch 36510: Loss: 0.9135, Accuracy: 0.5630\n",
      "Epoch 36610: Loss: 0.9371, Accuracy: 0.5556\n",
      "Epoch 36710: Loss: 0.9256, Accuracy: 0.5630\n",
      "Epoch 36810: Loss: 0.9156, Accuracy: 0.5630\n",
      "Epoch 36910: Loss: 0.9168, Accuracy: 0.5630\n",
      "Epoch 37010: Loss: 0.9315, Accuracy: 0.5630\n",
      "Epoch 37110: Loss: 1.0472, Accuracy: 0.5481\n",
      "Epoch 37210: Loss: 0.9127, Accuracy: 0.5630\n",
      "Epoch 37310: Loss: 0.9112, Accuracy: 0.5630\n",
      "Epoch 37410: Loss: 0.9114, Accuracy: 0.5630\n",
      "Epoch 37510: Loss: 0.9161, Accuracy: 0.5630\n",
      "Epoch 37610: Loss: 0.9294, Accuracy: 0.5556\n",
      "Epoch 37710: Loss: 0.9159, Accuracy: 0.5630\n",
      "Epoch 37810: Loss: 0.9222, Accuracy: 0.5630\n",
      "Epoch 37910: Loss: 0.9155, Accuracy: 0.5556\n",
      "Epoch 38010: Loss: 0.9195, Accuracy: 0.5630\n",
      "Epoch 38110: Loss: 0.9088, Accuracy: 0.5630\n",
      "Epoch 38210: Loss: 0.9161, Accuracy: 0.5630\n",
      "Epoch 38310: Loss: 0.9213, Accuracy: 0.5556\n",
      "Epoch 38410: Loss: 0.9258, Accuracy: 0.5630\n",
      "Epoch 38510: Loss: 0.9230, Accuracy: 0.5556\n",
      "Epoch 38610: Loss: 0.9903, Accuracy: 0.5481\n",
      "Epoch 38710: Loss: 0.9067, Accuracy: 0.5630\n",
      "Epoch 38810: Loss: 0.9065, Accuracy: 0.5630\n",
      "Epoch 38910: Loss: 0.9196, Accuracy: 0.5630\n",
      "Epoch 39010: Loss: 0.9633, Accuracy: 0.5556\n",
      "Epoch 39110: Loss: 0.9138, Accuracy: 0.5630\n",
      "Epoch 39210: Loss: 0.9052, Accuracy: 0.5630\n",
      "Epoch 39310: Loss: 0.9049, Accuracy: 0.5630\n",
      "Epoch 39410: Loss: 0.9104, Accuracy: 0.5556\n",
      "Epoch 39510: Loss: 0.9057, Accuracy: 0.5630\n",
      "Epoch 39610: Loss: 0.9308, Accuracy: 0.5556\n",
      "Epoch 39710: Loss: 1.2928, Accuracy: 0.4889\n",
      "Epoch 39810: Loss: 0.9035, Accuracy: 0.5630\n",
      "Epoch 39910: Loss: 0.9031, Accuracy: 0.5630\n",
      "Epoch 40010: Loss: 0.9058, Accuracy: 0.5630\n",
      "Epoch 40110: Loss: 0.9076, Accuracy: 0.5630\n",
      "Epoch 40210: Loss: 0.9084, Accuracy: 0.5556\n",
      "Epoch 40310: Loss: 0.9574, Accuracy: 0.5481\n",
      "Epoch 40410: Loss: 0.9230, Accuracy: 0.5556\n",
      "Epoch 40510: Loss: 0.9097, Accuracy: 0.5556\n",
      "Epoch 40610: Loss: 0.9465, Accuracy: 0.5556\n",
      "Epoch 40710: Loss: 1.0356, Accuracy: 0.5333\n",
      "Epoch 40810: Loss: 0.9006, Accuracy: 0.5630\n",
      "Epoch 40910: Loss: 0.9012, Accuracy: 0.5630\n",
      "Epoch 41010: Loss: 0.9018, Accuracy: 0.5630\n",
      "Epoch 41110: Loss: 0.9159, Accuracy: 0.5630\n",
      "Epoch 41210: Loss: 1.0406, Accuracy: 0.5481\n",
      "Epoch 41310: Loss: 0.9027, Accuracy: 0.5630\n",
      "Epoch 41410: Loss: 0.8991, Accuracy: 0.5630\n",
      "Epoch 41510: Loss: 0.8986, Accuracy: 0.5630\n",
      "Epoch 41610: Loss: 0.9006, Accuracy: 0.5630\n",
      "Epoch 41710: Loss: 0.9146, Accuracy: 0.5556\n",
      "Epoch 41810: Loss: 0.9968, Accuracy: 0.5481\n",
      "Epoch 41910: Loss: 0.8984, Accuracy: 0.5630\n",
      "Epoch 42010: Loss: 0.8977, Accuracy: 0.5630\n",
      "Epoch 42110: Loss: 0.8988, Accuracy: 0.5630\n",
      "Epoch 42210: Loss: 0.8984, Accuracy: 0.5630\n",
      "Epoch 42310: Loss: 0.9185, Accuracy: 0.5630\n",
      "Epoch 42410: Loss: 0.9034, Accuracy: 0.5630\n",
      "Epoch 42510: Loss: 0.8960, Accuracy: 0.5630\n",
      "Epoch 42610: Loss: 0.8956, Accuracy: 0.5630\n",
      "Epoch 42710: Loss: 0.8989, Accuracy: 0.5630\n",
      "Epoch 42810: Loss: 0.9232, Accuracy: 0.5556\n",
      "Epoch 42910: Loss: 0.9012, Accuracy: 0.5630\n",
      "Epoch 43010: Loss: 0.9054, Accuracy: 0.5556\n",
      "Epoch 43110: Loss: 0.9159, Accuracy: 0.5556\n",
      "Epoch 43210: Loss: 0.8950, Accuracy: 0.5630\n",
      "Epoch 43310: Loss: 0.8940, Accuracy: 0.5630\n",
      "Epoch 43410: Loss: 0.8943, Accuracy: 0.5630\n",
      "Epoch 43510: Loss: 0.9119, Accuracy: 0.5630\n",
      "Epoch 43610: Loss: 0.8991, Accuracy: 0.5630\n",
      "Epoch 43710: Loss: 0.9007, Accuracy: 0.5630\n",
      "Epoch 43810: Loss: 0.9082, Accuracy: 0.5556\n",
      "Epoch 43910: Loss: 1.1367, Accuracy: 0.5333\n",
      "Epoch 44010: Loss: 0.8924, Accuracy: 0.5630\n",
      "Epoch 44110: Loss: 0.8919, Accuracy: 0.5630\n",
      "Epoch 44210: Loss: 0.8916, Accuracy: 0.5630\n",
      "Epoch 44310: Loss: 0.8953, Accuracy: 0.5630\n",
      "Epoch 44410: Loss: 0.9251, Accuracy: 0.5630\n",
      "Epoch 44510: Loss: 0.9175, Accuracy: 0.5630\n",
      "Epoch 44610: Loss: 1.0560, Accuracy: 0.5259\n",
      "Epoch 44710: Loss: 0.8921, Accuracy: 0.5630\n",
      "Epoch 44810: Loss: 0.8969, Accuracy: 0.5630\n",
      "Epoch 44910: Loss: 0.9321, Accuracy: 0.5556\n",
      "Epoch 45010: Loss: 0.8945, Accuracy: 0.5630\n",
      "Epoch 45110: Loss: 0.8914, Accuracy: 0.5630\n",
      "Epoch 45210: Loss: 0.8930, Accuracy: 0.5630\n",
      "Epoch 45310: Loss: 0.9844, Accuracy: 0.5407\n",
      "Epoch 45410: Loss: 0.8921, Accuracy: 0.5630\n",
      "Epoch 45510: Loss: 0.8884, Accuracy: 0.5630\n",
      "Epoch 45610: Loss: 0.8886, Accuracy: 0.5630\n",
      "Epoch 45710: Loss: 0.8882, Accuracy: 0.5630\n",
      "Epoch 45810: Loss: 0.9037, Accuracy: 0.5630\n",
      "Epoch 45910: Loss: 0.8932, Accuracy: 0.5630\n",
      "Epoch 46010: Loss: 0.9039, Accuracy: 0.5556\n",
      "Epoch 46110: Loss: 0.8990, Accuracy: 0.5556\n",
      "Epoch 46210: Loss: 0.8927, Accuracy: 0.5630\n",
      "Epoch 46310: Loss: 0.9058, Accuracy: 0.5630\n",
      "Epoch 46410: Loss: 0.9170, Accuracy: 0.5481\n",
      "Epoch 46510: Loss: 0.8896, Accuracy: 0.5630\n",
      "Epoch 46610: Loss: 0.8875, Accuracy: 0.5630\n",
      "Epoch 46710: Loss: 0.8889, Accuracy: 0.5630\n",
      "Epoch 46810: Loss: 0.9065, Accuracy: 0.5556\n",
      "Epoch 46910: Loss: 1.0960, Accuracy: 0.5259\n",
      "Epoch 47010: Loss: 0.8846, Accuracy: 0.5630\n",
      "Epoch 47110: Loss: 0.8909, Accuracy: 0.5630\n",
      "Epoch 47210: Loss: 0.8850, Accuracy: 0.5630\n",
      "Epoch 47310: Loss: 0.8879, Accuracy: 0.5630\n",
      "Epoch 47410: Loss: 0.9811, Accuracy: 0.5407\n",
      "Epoch 47510: Loss: 0.8845, Accuracy: 0.5630\n",
      "Epoch 47610: Loss: 0.8893, Accuracy: 0.5630\n",
      "Epoch 47710: Loss: 0.8959, Accuracy: 0.5556\n",
      "Epoch 47810: Loss: 0.8939, Accuracy: 0.5630\n",
      "Epoch 47910: Loss: 0.8925, Accuracy: 0.5630\n",
      "Epoch 48010: Loss: 0.9033, Accuracy: 0.5556\n",
      "Epoch 48110: Loss: 1.0085, Accuracy: 0.5481\n",
      "Epoch 48210: Loss: 0.8844, Accuracy: 0.5630\n",
      "Epoch 48310: Loss: 0.8829, Accuracy: 0.5630\n",
      "Epoch 48410: Loss: 0.8823, Accuracy: 0.5630\n",
      "Epoch 48510: Loss: 0.8820, Accuracy: 0.5630\n",
      "Epoch 48610: Loss: 0.8820, Accuracy: 0.5630\n",
      "Epoch 48710: Loss: 0.8813, Accuracy: 0.5630\n",
      "Epoch 48810: Loss: 0.9059, Accuracy: 0.5630\n",
      "Epoch 48910: Loss: 0.9014, Accuracy: 0.5630\n",
      "Epoch 49010: Loss: 1.1431, Accuracy: 0.5333\n",
      "Epoch 49110: Loss: 0.8806, Accuracy: 0.5630\n",
      "Epoch 49210: Loss: 0.8804, Accuracy: 0.5630\n",
      "Epoch 49310: Loss: 0.9066, Accuracy: 0.5556\n",
      "Epoch 49410: Loss: 0.9205, Accuracy: 0.5556\n",
      "Epoch 49510: Loss: 0.9194, Accuracy: 0.5556\n",
      "Epoch 49610: Loss: 0.8793, Accuracy: 0.5630\n",
      "Epoch 49710: Loss: 0.8793, Accuracy: 0.5630\n",
      "Epoch 49810: Loss: 0.8900, Accuracy: 0.5630\n",
      "Epoch 49910: Loss: 1.0045, Accuracy: 0.5481\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "all_accuracies = []\n",
    "all_embeddings=[]\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out , embeddings= model(data)\n",
    "    loss = loss_fn(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, pred = out.max(dim=1)\n",
    "    correct = (pred == data.y).sum()\n",
    "    acc = int(correct) / data.y.size(0)\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "    all_accuracies.append(acc)\n",
    "    all_embeddings.append(embeddings)\n",
    "    \n",
    "    if epoch % 100 == 9 or epoch == 0:  \n",
    "        print(f\"Epoch {epoch+1:2d}: Loss: {loss.item():.4f}, Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred,embeddings= model(data)\n",
    "predicted_classes = y_pred.argmax(dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np = predicted_classes.cpu().numpy()\n",
    "actual_np = data.y.cpu().numpy()\n",
    "\n",
    "predicitons_df = pd.DataFrame({\n",
    "    'Actual': actual_np,\n",
    "    'Predicted': pred_np\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0        15         15\n",
       "1        16         15\n",
       "2        22         22\n",
       "3        23         23\n",
       "4         4         23\n",
       "..      ...        ...\n",
       "130      25         25\n",
       "131       6          6\n",
       "132       7          7\n",
       "133      10         10\n",
       "134       9          9\n",
       "\n",
       "[135 rows x 2 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicitons_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
